{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98f76ffd-b0c0-410d-9d0e-f84fb830edd0",
   "metadata": {},
   "source": [
    "# Requests et BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1daec809-f90b-4284-a372-1e4218fe949c",
   "metadata": {},
   "source": [
    "## Installation Des Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0799ce20-19e8-4225-aa45-aefa482222ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si nous n'avez pas encore installé ces packages il faut enlever les les lignes suivantes en commentaire etles executer\n",
    "# !pip install requests --upgrade --quiet\n",
    "# !pip install beautifulsoup4 --upgrade --quiet\n",
    "# !pip install pandas --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0970d7-e956-44d1-b517-f3bb927e2efd",
   "metadata": {},
   "source": [
    "## Importation des Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02f456c4-ce79-43e1-868d-8ac1737c10ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from random import randint\n",
    "from time import sleep\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fda70c2-716d-4f81-aee4-6098a755c851",
   "metadata": {},
   "source": [
    "## Comment sa fonctionne\n",
    "\n",
    "La première étape consiste à utiliser le package <code>**Requests**</code> pour télécharger le code HTML de notre page Web (à l'aide de la fonction <code>**requests.get**</code>) qui donne un objet de réponse. Nous pouvons voir si nous pouvons télécharger la page Web ou non en vérifiant la réponse. Statut de notre objet. (Il devrait être compris entre <code>**200 et 299**</code>). Ensuite, nous allons convertir cet objet de réponse en un objet <code>**BeautifulSoup**</code> en utilisant le constructeur <code>**BeautifulSoup()**</code>. Nous utiliserons cet objet pour inspecter notre document et extraire les données souhaitées. <code>**BeautifulSoup**</code> nécessite un argument supplémentaire appelé <code>**parser**</code>. (En bref, **BeautifulSoup** peut également être utilisé pour extraire des informations d'autres langages de balisage. Le **parser** par défaut est <code>**\"html.parser\"**</code>). Trouvez ci-dessous une fonction d'exemple indépendante qui effectuera la tâche ci-dessus: \n",
    "* de téléchargement des pages, \n",
    "* de vérification des réponses\n",
    "d'analyse à l'aide de <code>**BeautifulSoup()**</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5000412-4736-423b-859c-265e89114a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_item_page(items_url):\n",
    "    # télécharger la page\n",
    "    response = requests.get(items_url)\n",
    "    # vérifier le succès de réponse\n",
    "    if response.status_code != 200:\n",
    "        raise Exception('Failed to load page {}'.format(items_url))\n",
    "    # Parser la réponse à l'aide de beaufifulSoup\n",
    "    doc = BeautifulSoup(response.text, 'html.parser')\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7519f3-a43d-4443-90fb-fcafcb1e6b28",
   "metadata": {},
   "source": [
    "## Scraper la liste des articles de notre site Web cible\n",
    "Dans notre cas, nous allons scraper https://www.alibaba.com/trade/search?fsb=y&IndexArea=product_en&CatId=&SearchText=Inflight+Items&viewtype=G&tab={page} Nous obtiendrons une liste des produits en vol. Nous obtiendrons un **titre d'article principal**, un **prix**, **des notes** et une **URL** de page pour chaque article. Pour **chaque article**, nous obtiendrons plus de détails sur le produit à partir de la page de l'article (si nécessaire). Nous allons créer un dataframe de Pandas et un fichier **Json** avec les détails de l'élément. Pour chaque article, nous créerons également un fichier **CSV** au format indicatif suivant:\n",
    "\n",
    "nom, prix, URL\n",
    "Article JUNIO Fleur Préservée Avec Boîtes, 5.50 - 6.50, https://www.alibaba.com/product-detail/Item-JUNIO-Preserved-Flower-With-Boxes_62339028105.html?s=p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3f2ec73-b4a9-417c-b07f-26278a9a8edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.alibaba.com/trade/search?fsb=y&IndexArea=product_en&CatId=&SearchText=Inflight+Items&viewtype=G&tab=%7Bpage%7D\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2469970-b188-46fc-a376-3d0ac479273a",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = get_item_page(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1f2f41-cb1c-4471-a9fb-d0a5228e754f",
   "metadata": {},
   "source": [
    "## Comprendre les bases de BeautifulSoup\n",
    "\n",
    "**BeautifulSoup** a plusieurs méthodes pour extraire des informations de notre document analysé. La façon la plus simple de rechercher une balise dans notre document est d'appeler directement le nom de la balise que nous recherchons. Par exemple, si je veux la balise &lt;title&gt;, j'appellerai <code>doc.title</code>. Si je passe <code>doc.a</code>, il renverra l'occurrence de la première balise &lt;a&gt; présente dans mon document. Et si je voulais toutes les balises &lt;a&gt; ? Nous devons utiliser : « La méthode <code>find_all()</code> »."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18903233-6075-4ee7-af5a-9a92a87829bf",
   "metadata": {},
   "source": [
    "## BeautifulSoup: (.find_all() method)\n",
    "\n",
    "><code>doc.find_all(tag_name, attributes, limit, string, recursive=True)</code>:\n",
    "\n",
    "* tag_name: Le nom des éléments **HTML** ex: &lt;a&gt;, &lt;tr&gt;\n",
    "* attributes: un dict contenant les attributs d'une balise ex: {“class”: “abcabc”}\n",
    "* limit: un nombre pour limiter le nombre de balises sous cette correspondance.\n",
    "* String: une chaîne pour correspondre au contenu d'un élément \n",
    "* recursive: Par défaut, Beautiful Soup recherche tous les éléments enfants. Ainsi, le paramètre recursive = False limitera la recherche au premier élément trouvé et à son enfant uniquement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca78a3ce-b5a7-427f-b97c-9810a827af3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
